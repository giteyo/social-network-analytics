{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e13dc4-754c-4bcd-96e6-ee39ad4744ef",
   "metadata": {},
   "source": [
    "### This is used for extracting only amharic comments from an Ethiopian Music Clip called **á‹ˆáŠ•á‹µ áˆáŒ… á‰†áˆ¨áŒ ** by a famous Ethiopian Traditional musician named **Dagne Walle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cbb030-95a8-4280-b3ae-40abae30c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully scraped 2867 Amharic comments and saved to amharic_youtube_comments_UwOzBq8snm8.xlsx\n",
      "\n",
      "First few rows of the output DataFrame:\n",
      "  Comment ID               Author                 Time  \\\n",
      "0         C1           @dagnewale  2024-10-31T16:13:18   \n",
      "1         C2           @dawit7411  2025-05-04T17:22:55   \n",
      "2         C3  @MelakuTeferi-zl9qs  2025-05-04T12:51:20   \n",
      "3         C4     @andualembazezew  2025-05-04T07:55:11   \n",
      "4         C5     @andualembazezew  2025-05-04T07:54:48   \n",
      "\n",
      "                                        Comment Text  Likes  Reply Count  \n",
      "0  áŠ¨áˆá‰¥ áŠ áˆ˜áˆ°áŒáŠ“áˆˆáˆ ğŸ™ áŠ áˆµáˆ­ áˆšáˆŠá‹¨áŠ• áŠ¥á‹­á‰³ áŠ áŒáŠá‰°áŠ“áˆ á‹­áˆ„á‹°áŒáˆ á‹¨áˆ†áŠá‹ á‰ ...   2293          218  \n",
      "1   áŒ€áŒáŠ“á‰½áŠ• á‰ áŒ£áˆ áˆáˆ­áŒ¥ áˆµáˆ« áŠá‹ áŠ¥áŠ“áˆ˜áˆ°áŒáŠ“áˆˆáŠ• â¤â¤ğŸ™ğŸ™\\n12M view ğŸ˜â¤â¤â¤      1            0  \n",
      "2                áŠ¡áááááá á‹¨á‹ˆáŠ” áŠá‹³áŒ… á‹¨áˆ†áŠ á‰³áˆªáŠ«á‹Š áˆ™á‹šá‰ƒá¢ğŸ’ªğŸ’ªğŸ’ªğŸ’ªğŸ’ªğŸ’ª      0            0  \n",
      "3  á‰µáŠ­áŠ­áˆˆáŠ›áŠ“ á‰ áˆ°á‹‰ áˆáŒ… áŠ áˆáˆ® á‹«áˆˆ áŠ¥á‹‰áŠá‰µ áŠá‹‰ á¢ á‰ á‰°áˆˆá‹­ á‰ á‹šáˆ… á‹ˆá‰…á‰µ áˆˆáŠ ...      0            0  \n",
      "4  á‰µáŠ­áŠ­áˆˆáŠ›áŠ“ á‰ áˆ°á‹‰ áˆáŒ… áŠ áˆáˆ® á‹«áˆˆ áŠ¥á‹‰áŠá‰µ áŠá‹‰ á¢ á‰ á‰°áˆˆá‹­ á‰ á‹šáˆ… á‹ˆá‰…á‰µ áˆˆáŠ ...      0            0  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Replace with your actual API key\n",
    "api_key = \"   \"  # Make sure to insert your actual API key\n",
    "\n",
    "# Replace with the ID of the YouTube video you want to scrape comments from if you want other video.\n",
    "video_id = \"UwOzBq8snm8\"\n",
    "\n",
    "def clean_text_for_excel(text):\n",
    "    \"\"\"Removes or replaces characters that can cause issues in Excel.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Remove characters that are not valid in XML\n",
    "        text = re.sub(r\"[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]\", \"\", text)\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "def is_amharic(text):\n",
    "    \"\"\"\n",
    "    Checks if a given text contains Amharic characters.\n",
    "    This is a basic check and might not be perfect, but it's a good starting point.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return bool(re.search(r'[\\u1200-\\u137f]', text))  # Check for Ethiopic script\n",
    "    return False\n",
    "\n",
    "def get_comments_for_excel(youtube, video_id, max_results=100):\n",
    "    \"\"\"\n",
    "    Retrieves comments, filters for Amharic, and cleans the text for Excel compatibility.\n",
    "    \"\"\"\n",
    "    comments_data = []\n",
    "    comment_id_counter = 1\n",
    "    try:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet,replies\",\n",
    "            videoId=video_id,\n",
    "            maxResults=max_results,\n",
    "            textFormat=\"plainText\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        while response:\n",
    "            for item in response['items']:\n",
    "                snippet = item['snippet']['topLevelComment']['snippet']\n",
    "                comment_text = snippet['textDisplay']\n",
    "                # Check if the comment is Amharic before processing\n",
    "                if is_amharic(comment_text):\n",
    "                    comment_id = f\"C{comment_id_counter}\"\n",
    "                    author = snippet['authorDisplayName']\n",
    "                    timestamp = datetime.strptime(snippet['publishedAt'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                    time_formatted = timestamp.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "                    comment_text = clean_text_for_excel(comment_text)  # Clean the text\n",
    "                    likes = snippet['likeCount']\n",
    "                    reply_count = item['snippet'].get('totalReplyCount', 0)\n",
    "\n",
    "                    comments_data.append({\n",
    "                        'Comment ID': comment_id,\n",
    "                        'Author': author,\n",
    "                        'Time': time_formatted,\n",
    "                        'Comment Text': comment_text,\n",
    "                        'Likes': likes,\n",
    "                        'Reply Count': reply_count\n",
    "                    })\n",
    "                    comment_id_counter += 1\n",
    "\n",
    "            if 'nextPageToken' in response:\n",
    "                request = youtube.commentThreads().list(\n",
    "                    part=\"snippet,replies\",\n",
    "                    videoId=video_id,\n",
    "                    maxResults=max_results,\n",
    "                    pageToken=response['nextPageToken'],\n",
    "                    textFormat=\"plainText\"\n",
    "                )\n",
    "                response = request.execute()\n",
    "            else:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    return comments_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Build the YouTube API service object\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    # Get the comments\n",
    "    comments = get_comments_for_excel(youtube, video_id, max_results=100)\n",
    "\n",
    "    if comments:\n",
    "        # Create a Pandas DataFrame\n",
    "        df = pd.DataFrame(comments)\n",
    "\n",
    "        # Save the DataFrame to an Excel file\n",
    "        excel_filename = f\"amharic_youtube_comments_{video_id}.xlsx\"\n",
    "        try:\n",
    "            df.to_excel(excel_filename, index=False)\n",
    "            print(f\"Successfully scraped {len(comments)} Amharic comments and saved to {excel_filename}\")\n",
    "            print(\"\\nFirst few rows of the output DataFrame:\")\n",
    "            print(df.head())\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while saving to Excel: {e}\")\n",
    "    else:\n",
    "        print(f\"No Amharic comments found for video ID: {video_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6c98e-b3e0-43c7-b569-18b36618f3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
